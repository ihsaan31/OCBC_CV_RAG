{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_DEPLOYMENT_ID = os.getenv('AZURE_OPENAI_DEPLOYMENT_ID')\n",
    "AZURE_OPENAI_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "AZURE_API_VERSION = os.getenv('AZURE_API_VERSION')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"ocbc-cv-gpt\"  # change if desired\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_ID,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            temperature=0.0,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "embedding_llm = AzureOpenAIEmbeddings(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment='embedding-ada-crayon',\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "        )\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_llm)\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = \"\"\"IHSAN FATHYA\n",
    " 081283576216 | ihsanfathya@gmail.com | https://www.linkedin.com/in/ihsan-fathya/ | https://github.com/ihsaan31\n",
    " Bogor, Jawa Barat\n",
    " I'm an 8th-semester student with a genuine passion for technology, specifically in machine learning and Data Science. Drawing from a \n",
    "solid background in computer science and programming, I've developed a keen interest in utilizing Python to address complex problems \n",
    "and create innovative solutions.\n",
    " Work Experiences\n",
    " OCBC Indonesia -  Bsd, Tangerang Jun 2024 - Present\n",
    " Data Scientist Intern\n",
    " Oversea-Chinese Banking Corporation Limited (OCBC) is a Singaporean multinational banking and financial services corporation that \n",
    "provides a range of services to individuals, businesses, government agencies, and financial institutions.\n",
    " AI Compliance Chat Bot\n",
    " Developed a robust AI-powered compliance chatbot that integrates the regulatory frameworks of OJK, BI, and Sikepo. Leveraged \n",
    "LangChain to design and implement custom AI chains tailored for various tasks, including question routing, contextualization, and \n",
    "the generation of combined responses from multiple sources.\n",
    " Designed custom prompts and templates to optimize the performance of the AI models. These include templates for contextualizing \n",
    "questions, generating system responses, and creating combined answers by synthesizing data from multiple regulatory bodies.\n",
    " Implemented retrieval systems using various index managers (ElasticSearch, Redis) and graph databases (Neo4j) to fetch and \n",
    "merge relevant information, optimizing the accuracy of AI responses.\n",
    " FastAPI Development and API Integration\n",
    " Designed and implemented a RESTful API using FastAPI, enabling efficient communication between the front-end and backend \n",
    "services.\n",
    " Implemented real-time data streaming using 'StreamingResponse', allowing continuous delivery from LangChain.\n",
    " BMKG | Badan Meteorologi, Klimatologi, dan Geofisika -  \n",
    "Jakarta Pusat\n",
    " Oct 2023 - Dec 2023\n",
    " Artificial Intelligence Intern\n",
    " BMKG, based in Jakarta Pusat, is a key governmental organization in Indonesia. It plays a crucial role by providing essential information \n",
    "in meteorology, climatology, and geophysics. BMKG's services are integral to various sectors, including agriculture, transportation, \n",
    "disaster management, and public safety.\n",
    " Model Monitoring Dashboard\n",
    " Created a comprehensive web monitoring dashboard using Dash Plotly to evaluate and visualize model performance metrics \n",
    "effectively.\n",
    " Developed a separate monitoring dashboard utilizing Looker Studio, enhancing accessibility and usability.\n",
    " AI Modeling\n",
    " Applied Python extensively for AI modeling, including the conversion of an existing R model to Python resulting 10% improvment in \n",
    "accuracy.\n",
    " Developed and implemented a model for refining Numerical Weather Prediction using various machine learning algorithms, \n",
    "including Scikit-Learn and TensorFlow achieving 77% accuracy.\n",
    " PFI mega life -  Jakarta Selatan Feb 2023 - Jun 2023\n",
    " Data Analyst Intern\n",
    " PT PFI Mega Life Insurance is a joint venture with a new structure that combines the global expertise of Prudential Financial Inc. with the \n",
    "local market network strength of CT Corpora. PFI Mega Life provides a complete range of life insurance products to serve customers with \n",
    "a wide range, from large corporations to individuals.\n",
    " Leads Segmentation\n",
    " Integrated sentiment analysis and demographic results into leads segmentation, providing a nuanced understanding of leads \n",
    "engagement.\n",
    " Implemented K-means clustering algorithm for leads segmentation into distinct clusters.\n",
    " Sentiment Analysis\n",
    " Conducted sentiment analysis on a dataset of 6,000 Activity Content from CRM posts using Python and various libraries, including  \n",
    "NLTK, Sastrawi, pandas, numpy, matplotlib, and seaborn.\n",
    " Utilized the pre-trained Indonesia BERT model for sentiment analysis, resulting in a 10% increase in accuracy compared to \n",
    "traditional methods.\n",
    " Applied the model to categorize Activity Content into positive, neutral, or negative sentiments.\n",
    " Scrape LinkedIn Profile\n",
    " Executed a web scraping initiative using Beautiful Soup and Selenium in Python, successfully extracting over 14,000 leads from \n",
    "LinkedIn and search engine results, exceeding the initial target by 30%.\n",
    " Successfully navigated through LinkedIn profiles to capture demographic details, encompassing education information, current job \n",
    "roles, and past experience.\n",
    " Executed data extraction techniques to compile an Excel output file, streamlining the analysis of acquired leads.\n",
    " Education Level\n",
    " Universitas Gunadarma - Depok, Jawa Barat Aug 2020 - Sep 2024 (Expected)\n",
    " Bachelor Degree in Informatics Engineering, 3.41/4.00\n",
    " Skills, Achievements & Other Experience\n",
    " Certification (2021): Machine Learning  (Dicoding)\n",
    " Certification (2022): EF SET English Certificate 78/100 (C2 Proficient)\n",
    " Certification (2023): AI-900 - Microsoft Azure AI Fundamentals\n",
    " Certification (2023): Codecademy Data Scientist: Analytics Specialist Career Path\n",
    " Certification (2023): Codecademy Data Scientist: Inference Specialist Career Path\n",
    " Certification (2024): Codecademy Data Scientist: Machine Learning Specialist Career Pat\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_sumerrizer = \"\"\"\n",
    "Extract key details from a CV or resume, including name, contact information, work experience, education, skills, and certifications. Structure the output in a format optimized for a retriever system, ensuring each category is clearly labeled for easy indexing and retrieval.\n",
    " **User CV:** \n",
    " {cv}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QA_PROMPT = \"\"\"\n",
    "user question: {question}\n",
    "\n",
    "if the user question is not empty, ignore the text below!\n",
    "You are an AI job assistant. Based on the user's preferences, qualifications, and experience, evaluate the following job posting.\n",
    "\n",
    "1. Mention what jobs on the current listing\n",
    "2. Compare the user's CV/resume to the job listing, highlighting the key areas of alignment and any gaps.\n",
    "3. Assess whether the job is a match for the user's skills and experience. If the job matches, explain why. If it does not match, clearly state: \"Does not match.\"\n",
    "\n",
    "CV/Resume: \n",
    "{cv}\n",
    "\n",
    "Job Listing: \n",
    "{job_listing}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "# Assuming you have defined 'llm' and 'retriever' elsewhere in your code\n",
    "\n",
    "# CV summarizer chain\n",
    "cv_summarizer_prompt = PromptTemplate.from_template(CV_sumerrizer)\n",
    "cv_summarizer_chain = (\n",
    "    {\"cv\": RunnablePassthrough()} | cv_summarizer_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_prompt = PromptTemplate.from_template(QA_PROMPT)\n",
    "qa_chain = (\n",
    "    {\"cv\": RunnablePassthrough(),\n",
    "     \"job_listing\": RunnablePassthrough(),\n",
    "     \"question\": RunnablePassthrough(),} | qa_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Merged chain\n",
    "merged_rag_chain = (\n",
    "    {\n",
    "        \"cv\": RunnablePassthrough(),\n",
    "        \"job_listing\": RunnablePassthrough(),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | cv_summarizer_chain\n",
    "    | (lambda x: {\"job_listing\": retriever.invoke(x), \"cv\": x})\n",
    "    | qa_chain\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To improve their chances of being considered for the Marketing Technology Lead or Software Engineer positions, the user could highlight their relevant experience and skills in their CV/resume. They could also consider obtaining additional certifications or training in areas that align with the job requirements. Additionally, they could tailor their application materials to emphasize their transferable skills and showcase how their previous experiences can be applied to the desired roles.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_rag_chain.invoke({\"cv\": cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
