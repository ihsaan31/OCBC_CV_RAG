{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_DEPLOYMENT_ID = os.getenv('AZURE_OPENAI_DEPLOYMENT_ID')\n",
    "AZURE_OPENAI_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "AZURE_API_VERSION = os.getenv('AZURE_API_VERSION')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_ID,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            temperature=0.0,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "embedding_llm = AzureOpenAIEmbeddings(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment='embedding-ada-crayon',\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = \"\"\"IHSAN FATHYA\n",
    " 081283576216 | ihsanfathya@gmail.com | https://www.linkedin.com/in/ihsan-fathya/ | https://github.com/ihsaan31\n",
    " Bogor, Jawa Barat\n",
    " I'm an 8th-semester student with a genuine passion for technology, specifically in machine learning and Data Science. Drawing from a \n",
    "solid background in computer science and programming, I've developed a keen interest in utilizing Python to address complex problems \n",
    "and create innovative solutions.\n",
    " Work Experiences\n",
    " OCBC Indonesia -  Bsd, Tangerang Jun 2024 - Present\n",
    " Data Scientist Intern\n",
    " Oversea-Chinese Banking Corporation Limited (OCBC) is a Singaporean multinational banking and financial services corporation that \n",
    "provides a range of services to individuals, businesses, government agencies, and financial institutions.\n",
    " AI Compliance Chat Bot\n",
    " Developed a robust AI-powered compliance chatbot that integrates the regulatory frameworks of OJK, BI, and Sikepo. Leveraged \n",
    "LangChain to design and implement custom AI chains tailored for various tasks, including question routing, contextualization, and \n",
    "the generation of combined responses from multiple sources.\n",
    " Designed custom prompts and templates to optimize the performance of the AI models. These include templates for contextualizing \n",
    "questions, generating system responses, and creating combined answers by synthesizing data from multiple regulatory bodies.\n",
    " Implemented retrieval systems using various index managers (ElasticSearch, Redis) and graph databases (Neo4j) to fetch and \n",
    "merge relevant information, optimizing the accuracy of AI responses.\n",
    " FastAPI Development and API Integration\n",
    " Designed and implemented a RESTful API using FastAPI, enabling efficient communication between the front-end and backend \n",
    "services.\n",
    " Implemented real-time data streaming using 'StreamingResponse', allowing continuous delivery from LangChain.\n",
    " BMKG | Badan Meteorologi, Klimatologi, dan Geofisika -  \n",
    "Jakarta Pusat\n",
    " Oct 2023 - Dec 2023\n",
    " Artificial Intelligence Intern\n",
    " BMKG, based in Jakarta Pusat, is a key governmental organization in Indonesia. It plays a crucial role by providing essential information \n",
    "in meteorology, climatology, and geophysics. BMKG's services are integral to various sectors, including agriculture, transportation, \n",
    "disaster management, and public safety.\n",
    " Model Monitoring Dashboard\n",
    " Created a comprehensive web monitoring dashboard using Dash Plotly to evaluate and visualize model performance metrics \n",
    "effectively.\n",
    " Developed a separate monitoring dashboard utilizing Looker Studio, enhancing accessibility and usability.\n",
    " AI Modeling\n",
    " Applied Python extensively for AI modeling, including the conversion of an existing R model to Python resulting 10% improvment in \n",
    "accuracy.\n",
    " Developed and implemented a model for refining Numerical Weather Prediction using various machine learning algorithms, \n",
    "including Scikit-Learn and TensorFlow achieving 77% accuracy.\n",
    " PFI mega life -  Jakarta Selatan Feb 2023 - Jun 2023\n",
    " Data Analyst Intern\n",
    " PT PFI Mega Life Insurance is a joint venture with a new structure that combines the global expertise of Prudential Financial Inc. with the \n",
    "local market network strength of CT Corpora. PFI Mega Life provides a complete range of life insurance products to serve customers with \n",
    "a wide range, from large corporations to individuals.\n",
    " Leads Segmentation\n",
    " Integrated sentiment analysis and demographic results into leads segmentation, providing a nuanced understanding of leads \n",
    "engagement.\n",
    " Implemented K-means clustering algorithm for leads segmentation into distinct clusters.\n",
    " Sentiment Analysis\n",
    " Conducted sentiment analysis on a dataset of 6,000 Activity Content from CRM posts using Python and various libraries, including  \n",
    "NLTK, Sastrawi, pandas, numpy, matplotlib, and seaborn.\n",
    " Utilized the pre-trained Indonesia BERT model for sentiment analysis, resulting in a 10% increase in accuracy compared to \n",
    "traditional methods.\n",
    " Applied the model to categorize Activity Content into positive, neutral, or negative sentiments.\n",
    " Scrape LinkedIn Profile\n",
    " Executed a web scraping initiative using Beautiful Soup and Selenium in Python, successfully extracting over 14,000 leads from \n",
    "LinkedIn and search engine results, exceeding the initial target by 30%.\n",
    " Successfully navigated through LinkedIn profiles to capture demographic details, encompassing education information, current job \n",
    "roles, and past experience.\n",
    " Executed data extraction techniques to compile an Excel output file, streamlining the analysis of acquired leads.\n",
    " Education Level\n",
    " Universitas Gunadarma - Depok, Jawa Barat Aug 2020 - Sep 2024 (Expected)\n",
    " Bachelor Degree in Informatics Engineering, 3.41/4.00\n",
    " Skills, Achievements & Other Experience\n",
    " Certification (2021): Machine Learning  (Dicoding)\n",
    " Certification (2022): EF SET English Certificate 78/100 (C2 Proficient)\n",
    " Certification (2023): AI-900 - Microsoft Azure AI Fundamentals\n",
    " Certification (2023): Codecademy Data Scientist: Analytics Specialist Career Path\n",
    " Certification (2023): Codecademy Data Scientist: Inference Specialist Career Path\n",
    " Certification (2024): Codecademy Data Scientist: Machine Learning Specialist Career Pat\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"ocbc-cv-gpt\"  # change if desired\n",
    "index = pc.Index(index_name)\n",
    "llm = AzureChatOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_ID,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            temperature=0.0,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "embedding_llm = AzureOpenAIEmbeddings(\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            azure_deployment='embedding-ada-crayon',\n",
    "            api_key=AZURE_OPENAI_KEY,\n",
    "            api_version=AZURE_API_VERSION,\n",
    "        )\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_llm)\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from templates.prompt import QA_PROMPT\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(QA_PROMPT)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYou are an AI job assistant. Based on the user\\'s preferences, qualifications, and experience, evaluate the following job posting.\\n\\nCV/Resume: {question}\\nJob Listing: {context}\\n\\n1. Compare the user\\'s CV/resume to the job listing, highlighting the key areas of alignment and any gaps.\\n2. Assess whether the job is a match for the user\\'s skills and experience. If the job matches, explain why. If it does not match, clearly state: \"Does not match.\"\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_chain.invoke(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv summerizer chain\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from templates.prompt import QA_PROMPT, CV_sumerrizer\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(CV_sumerrizer)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_chain.invoke(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from templates.prompt import QA_PROMPT\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(QA_PROMPT)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_PROMPT = \"\"\"\n",
    "\n",
    "You are an AI job assistant. Based on the user's preferences, qualifications, and experience, evaluate the following job posting.\n",
    "\n",
    "\n",
    "\n",
    "1. Mention what jobs on the current listing\n",
    "2. Compare the user's CV/resume to the job listing, highlighting the key areas of alignment and any gaps.\n",
    "3. Assess whether the job is a match for the user's skills and experience. If the job matches, explain why. If it does not match, clearly state: \"Does not match.\"\n",
    "\n",
    "CV/Resume: {question}\n",
    "Job Listing: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYou are an AI job assistant. Based on the user\\'s preferences, qualifications, and experience, evaluate the following job posting.\\n\\n\\n\\n1. Mention what jobs on the current listing\\n2. Compare the user\\'s CV/resume to the job listing, highlighting the key areas of alignment and any gaps.\\n3. Assess whether the job is a match for the user\\'s skills and experience. If the job matches, explain why. If it does not match, clearly state: \"Does not match.\"\\n\\nCV/Resume: {question}\\nJob Listing: {context}\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from templates.prompt import CV_sumerrizer, contextualize_q_system_prompt\n",
    "\n",
    "# Assuming you have defined 'llm' and 'retriever' elsewhere in your code\n",
    "\n",
    "# CV summarizer chain\n",
    "cv_summarizer_prompt = PromptTemplate.from_template(CV_sumerrizer)\n",
    "cv_summarizer_chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | cv_summarizer_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_prompt = PromptTemplate.from_template(QA_PROMPT)\n",
    "\n",
    "# Merged chain\n",
    "merged_rag_chain = (\n",
    "    {\"question\": RunnablePassthrough(), \"context\": RunnablePassthrough(), \"chat_history\": RunnablePassthrough()}\n",
    "    | cv_summarizer_chain\n",
    "    | (lambda x: {\"context\": retriever.invoke(x), \"question\": x, \"chat_history\": x})\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The current job listing includes the following positions:\n",
      "- Marketing Technology Lead\n",
      "- FCC Specialist\n",
      "- Software Engineer\n",
      "- Business Performance Management Head\n",
      "- Appraisal Head\n",
      "\n",
      "2. Comparing the user's CV/resume to the job listing, there is a mismatch between the user's qualifications and the job requirements. The user's CV/resume highlights skills and experience in machine learning, data science, and programming, which do not directly align with the job requirements listed in the job posting.\n",
      "\n",
      "3. The job does not match the user's skills and experience. The user's background in machine learning, data science, and programming does not directly align with the job requirements listed in the job posting, which include experience in project management, digital marketing, and CRM platforms.\n"
     ]
    }
   ],
   "source": [
    "print(merged_rag_chain.invoke(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yang amriz bikin \n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from templates.prompt import CV_sumerrizer, contextualize_q_system_prompt\n",
    "\n",
    "# Assuming you have defined 'llm' and 'retriever' elsewhere in your code\n",
    "\n",
    "# CV summarizer chain\n",
    "cv_summarizer_prompt = PromptTemplate.from_template(CV_sumerrizer)\n",
    "\n",
    "cv_summarizer_chain = (\n",
    "    # {\"question\": RunnablePassthrough()}\n",
    "    cv_summarizer_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_prompt = PromptTemplate.from_template(QA_PROMPT)\n",
    "\n",
    "# # Merged chain\n",
    "merged_rag_chain = (\n",
    "    # {\"question\": RunnablePassthrough()}\n",
    "    \n",
    "    # {\"contexty\": RunnablePassthrough(),\"chat_history\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "    RunnablePassthrough()\n",
    "    | {\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        \"context\": itemgetter(\"question\") | retriever\n",
    "    } | RunnablePassthrough()\n",
    "    | {\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        \"context\": itemgetter(\"context\"),\n",
    "        \"question\": {\"question\": itemgetter(\"question\")} | cv_summarizer_chain\n",
    "    } | RunnablePassthrough()\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | {\n",
    "        \"answer\": StrOutputParser(),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    # cv_summarizer_prompt,\n",
    "    merged_rag_chain,\n",
    "    get_session_history = get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key= \"answer\",\n",
    "    history_factory_config= [\n",
    "        ConfigurableFieldSpec (\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for session.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"question\": cv},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"apa aja\"}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Key areas of alignment between the user's CV/resume and the job listing include:\n",
      "- Experience in developing AI-powered chatbots, implementing retrieval systems, and creating web monitoring dashboards aligns with the requirement for experience in project management and collaboration with IT teams.\n",
      "- Skills in Python, Machine Learning, Data Science, AI, and various libraries and frameworks align with the requirement for knowledge in marketing automation platforms, CMS, and marketing analytics.\n",
      "- Experience in sentiment analysis and web scraping aligns with the requirement for experience in data analysis and integration of data systems.\n",
      "\n",
      "Gaps between the user's CV/resume and the job listing include:\n",
      "- The job listing mentions specific platforms and tools related to marketing automation and digital marketing that are not mentioned in the user's CV/resume.\n",
      "- The job listing emphasizes project management and collaboration with various teams, while the user's CV/resume does not explicitly mention experience in these areas.\n",
      "\n",
      "2. The job does not match the user's skills and experience completely. While the user has relevant experience in data science, AI, and web scraping, there are specific requirements related to marketing automation platforms and project management that are not mentioned in the user's CV/resume. However, the user's skills in Python, Machine Learning, and Data Science could be transferable to the role, and their experience in developing AI-powered chatbots and implementing retrieval systems could be valuable in a marketing technology role.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apa aja': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"IHSAN FATHYA\\n 081283576216 | ihsanfathya@gmail.com | https://www.linkedin.com/in/ihsan-fathya/ | https://github.com/ihsaan31\\n Bogor, Jawa Barat\\n I'm an 8th-semester student with a genuine passion for technology, specifically in machine learning and Data Science. Drawing from a \\nsolid background in computer science and programming, I've developed a keen interest in utilizing Python to address complex problems \\nand create innovative solutions.\\n Work Experiences\\n OCBC Indonesia -  Bsd, Tangerang Jun 2024 - Present\\n Data Scientist Intern\\n Oversea-Chinese Banking Corporation Limited (OCBC) is a Singaporean multinational banking and financial services corporation that \\nprovides a range of services to individuals, businesses, government agencies, and financial institutions.\\n AI Compliance Chat Bot\\n Developed a robust AI-powered compliance chatbot that integrates the regulatory frameworks of OJK, BI, and Sikepo. Leveraged \\nLangChain to design and implement custom AI chains tailored for various tasks, including question routing, contextualization, and \\nthe generation of combined responses from multiple sources.\\n Designed custom prompts and templates to optimize the performance of the AI models. These include templates for contextualizing \\nquestions, generating system responses, and creating combined answers by synthesizing data from multiple regulatory bodies.\\n Implemented retrieval systems using various index managers (ElasticSearch, Redis) and graph databases (Neo4j) to fetch and \\nmerge relevant information, optimizing the accuracy of AI responses.\\n FastAPI Development and API Integration\\n Designed and implemented a RESTful API using FastAPI, enabling efficient communication between the front-end and backend \\nservices.\\n Implemented real-time data streaming using 'StreamingResponse', allowing continuous delivery from LangChain.\\n BMKG | Badan Meteorologi, Klimatologi, dan Geofisika -  \\nJakarta Pusat\\n Oct 2023 - Dec 2023\\n Artificial Intelligence Intern\\n BMKG, based in Jakarta Pusat, is a key governmental organization in Indonesia. It plays a crucial role by providing essential information \\nin meteorology, climatology, and geophysics. BMKG's services are integral to various sectors, including agriculture, transportation, \\ndisaster management, and public safety.\\n Model Monitoring Dashboard\\n Created a comprehensive web monitoring dashboard using Dash Plotly to evaluate and visualize model performance metrics \\neffectively.\\n Developed a separate monitoring dashboard utilizing Looker Studio, enhancing accessibility and usability.\\n AI Modeling\\n Applied Python extensively for AI modeling, including the conversion of an existing R model to Python resulting 10% improvment in \\naccuracy.\\n Developed and implemented a model for refining Numerical Weather Prediction using various machine learning algorithms, \\nincluding Scikit-Learn and TensorFlow achieving 77% accuracy.\\n PFI mega life -  Jakarta Selatan Feb 2023 - Jun 2023\\n Data Analyst Intern\\n PT PFI Mega Life Insurance is a joint venture with a new structure that combines the global expertise of Prudential Financial Inc. with the \\nlocal market network strength of CT Corpora. PFI Mega Life provides a complete range of life insurance products to serve customers with \\na wide range, from large corporations to individuals.\\n Leads Segmentation\\n Integrated sentiment analysis and demographic results into leads segmentation, providing a nuanced understanding of leads \\nengagement.\\n Implemented K-means clustering algorithm for leads segmentation into distinct clusters.\\n Sentiment Analysis\\n Conducted sentiment analysis on a dataset of 6,000 Activity Content from CRM posts using Python and various libraries, including  \\nNLTK, Sastrawi, pandas, numpy, matplotlib, and seaborn.\\n Utilized the pre-trained Indonesia BERT model for sentiment analysis, resulting in a 10% increase in accuracy compared to \\ntraditional methods.\\n Applied the model to categorize Activity Content into positive, neutral, or negative sentiments.\\n Scrape LinkedIn Profile\\n Executed a web scraping initiative using Beautiful Soup and Selenium in Python, successfully extracting over 14,000 leads from \\nLinkedIn and search engine results, exceeding the initial target by 30%.\\n Successfully navigated through LinkedIn profiles to capture demographic details, encompassing education information, current job \\nroles, and past experience.\\n Executed data extraction techniques to compile an Excel output file, streamlining the analysis of acquired leads.\\n Education Level\\n Universitas Gunadarma - Depok, Jawa Barat Aug 2020 - Sep 2024 (Expected)\\n Bachelor Degree in Informatics Engineering, 3.41/4.00\\n Skills, Achievements & Other Experience\\n Certification (2021): Machine Learning  (Dicoding)\\n Certification (2022): EF SET English Certificate 78/100 (C2 Proficient)\\n Certification (2023): AI-900 - Microsoft Azure AI Fundamentals\\n Certification (2023): Codecademy Data Scientist: Analytics Specialist Career Path\\n Certification (2023): Codecademy Data Scientist: Inference Specialist Career Path\\n Certification (2024): Codecademy Data Scientist: Machine Learning Specialist Career Pat\"), AIMessage(content=\"1. Key areas of alignment between the user's CV/resume and the job listing include:\\n- Experience in developing AI-powered chatbots, implementing retrieval systems, and creating web monitoring dashboards aligns with the requirement for experience in project management and collaboration with IT teams.\\n- Skills in Python, Machine Learning, Data Science, AI, and various libraries and frameworks align with the requirement for knowledge in marketing automation platforms, CMS, and marketing analytics.\\n- Experience in sentiment analysis and web scraping aligns with the requirement for experience in data analysis and integration of data systems.\\n\\nGaps between the user's CV/resume and the job listing include:\\n- The job listing mentions specific platforms and tools related to marketing automation and digital marketing that are not mentioned in the user's CV/resume.\\n- The job listing emphasizes project management and collaboration with various teams, while the user's CV/resume does not explicitly mention experience in these areas.\\n\\n2. The job does not match the user's skills and experience completely. While the user has relevant experience in data science, AI, and web scraping, there are specific requirements related to marketing automation platforms and project management that are not mentioned in the user's CV/resume. However, the user's skills in Python, Machine Learning, and Data Science could be transferable to the role, and their experience in developing AI-powered chatbots and implementing retrieval systems could be valuable in a marketing technology role.\")])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocbc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
